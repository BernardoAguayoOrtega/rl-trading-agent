{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c27de0c6",
   "metadata": {},
   "source": [
    "# ğŸ‰ PHASE 1 COMPLETE! âœ…\n",
    "\n",
    "## Implementation Status\n",
    "\n",
    "### âœ… COMPLETED: Phase 1 - Environment Setup\n",
    "- **âœ… Project Structure**: `uv` package manager, proper Python project layout\n",
    "- **âœ… Dependencies**: All required packages installed (OpenAI, yfinance, pandas, numpy, scikit-learn, ta-lib, matplotlib, etc.)\n",
    "- **âœ… Configuration System**: Comprehensive config management with dataclasses\n",
    "- **âœ… OpenAI Integration**: AI client wrapper with trading-specific prompts\n",
    "- **âœ… Testing Framework**: Complete test suite for Phase 1 validation\n",
    "- **âœ… Environment Setup**: Scripts for easy project initialization\n",
    "\n",
    "### ğŸš§ NEXT: Phase 2 - Intelligent Data Management\n",
    "- Yahoo Finance integration\n",
    "- Real-time data pipeline\n",
    "- Data validation and cleaning\n",
    "- Technical indicator calculation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f4585",
   "metadata": {},
   "source": [
    "# AI TRADING AGENT - COMPREHENSIVE DEVELOPMENT PLAN\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project aims to develop an intelligent trading agent that leverages:\n",
    "- **OpenAI SDK** for decision-making intelligence\n",
    "- **Existing professional-grade backtesting framework** \n",
    "- **Comprehensive technical indicators library**\n",
    "- **Automated data management and validation**\n",
    "\n",
    "### Key Advantages of This Approach:\n",
    "âœ… **Solid Foundation**: Leveraging your proven backtesting framework  \n",
    "âœ… **Professional Quality**: Industry-standard validation methods  \n",
    "âœ… **AI-Powered**: Intelligent decision making via OpenAI  \n",
    "âœ… **Comprehensive Testing**: Multiple validation techniques  \n",
    "âœ… **Risk Management**: Built-in SL/TP and position sizing  \n",
    "\n",
    "---\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Data Layer    â”‚    â”‚  Indicator      â”‚    â”‚  AI Agent       â”‚\n",
    "â”‚                 â”‚    â”‚  Library        â”‚    â”‚  (OpenAI)       â”‚\n",
    "â”‚ â€¢ Yahoo Finance â”‚â”€â”€â”€â”€â–¶â”‚ â€¢ 20+ Indicatorsâ”‚â”€â”€â”€â”€â–¶â”‚ â€¢ Decision      â”‚\n",
    "â”‚ â€¢ Data Cleaning â”‚    â”‚ â€¢ Custom Built  â”‚    â”‚ â€¢ Strategy      â”‚\n",
    "â”‚ â€¢ IS/OS Split   â”‚    â”‚ â€¢ Transparent   â”‚    â”‚ â€¢ Learning      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "          â”‚                       â”‚                       â”‚\n",
    "          â”‚                       â”‚                       â”‚\n",
    "          â–¼                       â–¼                       â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Backtesting    â”‚    â”‚  Validation     â”‚    â”‚  Performance    â”‚\n",
    "â”‚  Framework      â”‚    â”‚  Suite          â”‚    â”‚  Analytics      â”‚\n",
    "â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚\n",
    "â”‚ â€¢ Professional  â”‚    â”‚ â€¢ Walk Forward  â”‚    â”‚ â€¢ Risk Metrics  â”‚\n",
    "â”‚ â€¢ P&L Tracking  â”‚    â”‚ â€¢ Monte Carlo   â”‚    â”‚ â€¢ Optimization  â”‚\n",
    "â”‚ â€¢ Risk Mgmt     â”‚    â”‚ â€¢ Cross Val     â”‚    â”‚ â€¢ Reporting     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0883ff8",
   "metadata": {},
   "source": [
    "# PHASE 1: ENVIRONMENT SETUP AND DEPENDENCIES\n",
    "\n",
    "## Required Libraries and Tools\n",
    "\n",
    "### Core Dependencies\n",
    "- **OpenAI SDK**: For AI agent intelligence\n",
    "- **yfinance**: Market data acquisition\n",
    "- **pandas/numpy**: Data manipulation\n",
    "- **matplotlib/seaborn**: Visualization\n",
    "- **jupyter**: Development environment\n",
    "\n",
    "### Your Existing Framework\n",
    "- **Technical Indicators Library**: Complete set of 20+ indicators\n",
    "- **Backtesting Framework**: Professional-grade validation system\n",
    "- **Optimization Tools**: Parameter tuning and validation\n",
    "\n",
    "## Installation Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core AI and Data Libraries\n",
    "!pip install openai\n",
    "!pip install yfinance\n",
    "!pip install pandas numpy matplotlib seaborn\n",
    "!pip install scikit-learn\n",
    "!pip install plotly\n",
    "\n",
    "# Optional: Enhanced visualization and analysis\n",
    "!pip install mplfinance  # Financial charts\n",
    "!pip install ta-lib      # Additional technical analysis (if needed)\n",
    "!pip install pandas-ta   # Extended technical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a5a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# OpenAI SDK\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Import your existing framework functions\n",
    "# Note: We'll need to modularize your existing code into Python files\n",
    "# from indicators import *  # All technical indicators\n",
    "# from framework import *   # Backtesting framework\n",
    "# from validation import *  # Validation methods\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(\"ğŸ¤– OpenAI SDK ready for agent development\")\n",
    "print(\"ğŸ“Š Your existing framework integration ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c43e28d",
   "metadata": {},
   "source": [
    "# PHASE 2: DATA ACQUISITION FROM YAHOO FINANCE\n",
    "\n",
    "## Enhanced Data Management System\n",
    "\n",
    "Building upon your existing data handling capabilities, we'll create an intelligent data acquisition system that:\n",
    "\n",
    "- **Automated Downloads**: Fetch data for multiple assets\n",
    "- **Data Quality Checks**: Validate completeness and accuracy  \n",
    "- **Flexible Timeframes**: Support multiple trading timeframes\n",
    "- **Error Handling**: Robust data retrieval with fallbacks\n",
    "- **Caching System**: Efficient data storage and retrieval\n",
    "\n",
    "## Data Acquisition Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntelligentDataManager:\n",
    "    \"\"\"\n",
    "    Enhanced data acquisition system for AI trading agent\n",
    "    Builds upon your existing data handling capabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir='data_cache'):\n",
    "        self.cache_dir = cache_dir\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        \n",
    "    def download_market_data(self, symbols, start_date, end_date, interval='1d'):\n",
    "        \"\"\"\n",
    "        Download market data with intelligent caching and error handling\n",
    "        \"\"\"\n",
    "        all_data = {}\n",
    "        failed_downloads = []\n",
    "        \n",
    "        for symbol in symbols:\n",
    "            try:\n",
    "                print(f\"ğŸ“¥ Downloading {symbol}...\")\n",
    "                data = yf.download(symbol, start=start_date, end=end_date, \n",
    "                                 interval=interval, auto_adjust=True, \n",
    "                                 prepost=True, threads=True)\n",
    "                \n",
    "                if not data.empty:\n",
    "                    # Data quality checks\n",
    "                    data = self._clean_data(data, symbol)\n",
    "                    all_data[symbol] = data\n",
    "                    # Cache the data\n",
    "                    self._cache_data(data, symbol, interval)\n",
    "                    print(f\"âœ… {symbol}: {len(data)} records\")\n",
    "                else:\n",
    "                    failed_downloads.append(symbol)\n",
    "                    print(f\"âŒ {symbol}: No data available\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                failed_downloads.append(symbol)\n",
    "                print(f\"âŒ {symbol}: Error - {str(e)}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Successfully downloaded: {len(all_data)} assets\")\n",
    "        if failed_downloads:\n",
    "            print(f\"âš ï¸  Failed downloads: {failed_downloads}\")\n",
    "            \n",
    "        return all_data, failed_downloads\n",
    "    \n",
    "    def _clean_data(self, data, symbol):\n",
    "        \"\"\"Enhanced data cleaning based on your framework\"\"\"\n",
    "        # Remove duplicates\n",
    "        data = data[~data.index.duplicated(keep='first')]\n",
    "        \n",
    "        # Forward fill missing values (limited)\n",
    "        data = data.fillna(method='ffill', limit=3)\n",
    "        \n",
    "        # Remove rows where all OHLC values are the same (market closed)\n",
    "        mask = ~((data['Open'] == data['High']) & \n",
    "                 (data['High'] == data['Low']) & \n",
    "                 (data['Low'] == data['Close']))\n",
    "        data = data[mask]\n",
    "        \n",
    "        # Ensure minimum data requirements\n",
    "        if len(data) < 200:  # Minimum for technical indicators\n",
    "            print(f\"âš ï¸  {symbol}: Limited data ({len(data)} records)\")\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    def _cache_data(self, data, symbol, interval):\n",
    "        \"\"\"Cache downloaded data\"\"\"\n",
    "        filename = f\"{symbol}_{interval}_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "        filepath = os.path.join(self.cache_dir, filename)\n",
    "        data.to_csv(filepath)\n",
    "        \n",
    "    def get_asset_universe(self):\n",
    "        \"\"\"Predefined universe of liquid, tradeable assets\"\"\"\n",
    "        return {\n",
    "            'major_indices': ['SPY', 'QQQ', 'IWM', 'VTI'],\n",
    "            'tech_stocks': ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA'],\n",
    "            'financial': ['JPM', 'BAC', 'WFC', 'GS'],\n",
    "            'crypto': ['BTC-USD', 'ETH-USD'],\n",
    "            'forex': ['EURUSD=X', 'GBPUSD=X'],\n",
    "            'commodities': ['GLD', 'SLV', 'USO']\n",
    "        }\n",
    "\n",
    "# Initialize the data manager\n",
    "data_manager = IntelligentDataManager()\n",
    "print(\"ğŸ—ï¸  Intelligent Data Manager initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8426e410",
   "metadata": {},
   "source": [
    "# PHASE 3: TECHNICAL INDICATORS INTEGRATION\n",
    "\n",
    "## Modular Indicator System\n",
    "\n",
    "Your existing technical indicators library is excellent! We'll integrate it into a modular system that the AI agent can use dynamically:\n",
    "\n",
    "### Key Features:\n",
    "- **20+ Professional Indicators**: Your custom-built library\n",
    "- **Dynamic Selection**: AI can choose which indicators to use\n",
    "- **Parameter Optimization**: Automated parameter tuning\n",
    "- **Indicator Combinations**: Create complex indicator strategies\n",
    "- **Performance Tracking**: Monitor indicator effectiveness\n",
    "\n",
    "### Integration Strategy:\n",
    "1. **Modularize** your existing indicator functions\n",
    "2. **Create indicator factory** for dynamic instantiation  \n",
    "3. **Add metadata** for AI understanding\n",
    "4. **Implement caching** for performance\n",
    "5. **Enable real-time** calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TechnicalIndicatorFactory:\n",
    "    \"\"\"\n",
    "    Modular system to integrate your existing indicator library\n",
    "    Enables AI agent to dynamically use and combine indicators\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.indicator_registry = self._build_indicator_registry()\n",
    "        \n",
    "    def _build_indicator_registry(self):\n",
    "        \"\"\"Registry of all available indicators with metadata\"\"\"\n",
    "        return {\n",
    "            # Price-based indicators\n",
    "            'sma': {\n",
    "                'function': self.ocpSma,\n",
    "                'category': 'trend',\n",
    "                'description': 'Simple Moving Average - trend following',\n",
    "                'parameters': {'periodo': 20, 'col': 'Close'},\n",
    "                'min_data_points': 20,\n",
    "                'output_columns': ['s{periodo}']\n",
    "            },\n",
    "            'ema': {\n",
    "                'function': self.ocpExp,\n",
    "                'category': 'trend', \n",
    "                'description': 'Exponential Moving Average - responsive trend',\n",
    "                'parameters': {'periodo': 20, 'col': 'Close'},\n",
    "                'min_data_points': 20,\n",
    "                'output_columns': ['e{periodo}']\n",
    "            },\n",
    "            'rsi': {\n",
    "                'function': self.ocpRsi,\n",
    "                'category': 'momentum',\n",
    "                'description': 'Relative Strength Index - momentum oscillator',\n",
    "                'parameters': {'periodo': 14, 'col': 'Close'},\n",
    "                'min_data_points': 30,\n",
    "                'output_columns': ['rsi{periodo}']\n",
    "            },\n",
    "            'macd': {\n",
    "                'function': self.ocpMacd,\n",
    "                'category': 'momentum',\n",
    "                'description': 'MACD - trend and momentum',\n",
    "                'parameters': {'fast': 12, 'slow': 26, 'suavizado': 9, 'col': 'Close'},\n",
    "                'min_data_points': 35,\n",
    "                'output_columns': ['macd{fast}{slow}{suavizado}', 'signal', 'mTrend']\n",
    "            },\n",
    "            'bb': {\n",
    "                'function': self.ocpBb,\n",
    "                'category': 'volatility',\n",
    "                'description': 'Bollinger Bands - volatility and support/resistance',\n",
    "                'parameters': {'periodo': 20, 'desvios': 2, 'col': 'Close'},\n",
    "                'min_data_points': 20,\n",
    "                'output_columns': ['bs{periodo}', 'bInf', 'bSup']\n",
    "            },\n",
    "            'atr': {\n",
    "                'function': self.ocpAtr,\n",
    "                'category': 'volatility',\n",
    "                'description': 'Average True Range - volatility measure',\n",
    "                'parameters': {'periodo': 14},\n",
    "                'min_data_points': 14,\n",
    "                'output_columns': ['atr{periodo}', 'atr%{periodo}']\n",
    "            }\n",
    "            # Add more indicators from your library...\n",
    "        }\n",
    "    \n",
    "    def calculate_indicator(self, data, indicator_name, **kwargs):\n",
    "        \"\"\"Calculate a specific indicator with custom parameters\"\"\"\n",
    "        if indicator_name not in self.indicator_registry:\n",
    "            raise ValueError(f\"Indicator {indicator_name} not found in registry\")\n",
    "            \n",
    "        indicator_info = self.indicator_registry[indicator_name]\n",
    "        \n",
    "        # Merge default parameters with provided kwargs\n",
    "        params = indicator_info['parameters'].copy()\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        # Check minimum data requirements\n",
    "        min_points = indicator_info['min_data_points']\n",
    "        if len(data) < min_points:\n",
    "            raise ValueError(f\"Insufficient data: need {min_points}, got {len(data)}\")\n",
    "        \n",
    "        # Calculate indicator\n",
    "        result_data = indicator_info['function'](data.copy(), **params)\n",
    "        return result_data\n",
    "    \n",
    "    def calculate_indicator_suite(self, data, indicator_list=None):\n",
    "        \"\"\"Calculate multiple indicators efficiently\"\"\"\n",
    "        if indicator_list is None:\n",
    "            # Default comprehensive suite\n",
    "            indicator_list = [\n",
    "                ('sma', {'periodo': 20}),\n",
    "                ('sma', {'periodo': 50}),\n",
    "                ('sma', {'periodo': 200}),\n",
    "                ('ema', {'periodo': 12}),\n",
    "                ('rsi', {'periodo': 14}),\n",
    "                ('macd', {}),\n",
    "                ('bb', {}),\n",
    "                ('atr', {})\n",
    "            ]\n",
    "        \n",
    "        result_data = data.copy()\n",
    "        calculated_indicators = []\n",
    "        \n",
    "        for indicator_name, params in indicator_list:\n",
    "            try:\n",
    "                result_data = self.calculate_indicator(result_data, indicator_name, **params)\n",
    "                calculated_indicators.append((indicator_name, params))\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Failed to calculate {indicator_name}: {e}\")\n",
    "        \n",
    "        print(f\"âœ… Calculated {len(calculated_indicators)} indicators\")\n",
    "        return result_data, calculated_indicators\n",
    "    \n",
    "    def get_indicator_categories(self):\n",
    "        \"\"\"Get indicators grouped by category for AI understanding\"\"\"\n",
    "        categories = {}\n",
    "        for name, info in self.indicator_registry.items():\n",
    "            category = info['category']\n",
    "            if category not in categories:\n",
    "                categories[category] = []\n",
    "            categories[category].append({\n",
    "                'name': name,\n",
    "                'description': info['description']\n",
    "            })\n",
    "        return categories\n",
    "    \n",
    "    # Your existing indicator functions (adapted for the factory)\n",
    "    def ocpSma(self, df, periodo=20, borraNan=False, col='Close'):\n",
    "        \"\"\"Simple Moving Average - from your indicators library\"\"\"\n",
    "        df[f's{periodo}'] = df[col].rolling(periodo).mean()\n",
    "        if borraNan: \n",
    "            df.dropna(inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def ocpExp(self, df, periodo=20, borraNan=False, col='Close'):\n",
    "        \"\"\"Exponential Moving Average - from your indicators library\"\"\"\n",
    "        df[f'e{periodo}'] = df[col].ewm(span=periodo).mean()\n",
    "        if borraNan: \n",
    "            df.dropna(inplace=True)\n",
    "        return df\n",
    "        \n",
    "    def ocpRsi(self, df, periodo=14, borraNan=False, col='Close'):\n",
    "        \"\"\"RSI - from your indicators library\"\"\"\n",
    "        df['dif'] = df[col].diff()\n",
    "        df['win'] = np.where(df['dif'] > 0, df['dif'], 0)\n",
    "        df['loss'] = np.where(df['dif'] < 0, abs(df['dif']), 0)\n",
    "        df['emaWin'] = df.win.ewm(span=periodo).mean()\n",
    "        df['emaLoss'] = df.loss.ewm(span=periodo).mean()\n",
    "        df['rs'] = df.emaWin / df.emaLoss\n",
    "        df[f'rsi{periodo}'] = 100 - (100 / (1 + df.rs))\n",
    "        df.drop(['dif', 'win', 'loss', 'emaWin', 'emaLoss', 'rs'], axis=1, inplace=True)\n",
    "        if borraNan: \n",
    "            df.dropna(inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def ocpMacd(self, df, fast=12, slow=26, suavizado=9, borraNan=False, col='Close'):\n",
    "        \"\"\"MACD - from your indicators library\"\"\"\n",
    "        df['emaFast'] = df[col].ewm(span=fast).mean()\n",
    "        df['emaSlow'] = df[col].ewm(span=slow).mean()\n",
    "        df[f'macd{fast}{slow}{suavizado}'] = df.emaFast - df.emaSlow\n",
    "        df['signal'] = df[f'macd{fast}{slow}{suavizado}'].ewm(span=suavizado).mean()\n",
    "        df['mTrend'] = np.where(df[f'macd{fast}{slow}{suavizado}'] > df['signal'], 'A', 'B')\n",
    "        df.drop(['emaFast', 'emaSlow'], axis=1, inplace=True)\n",
    "        if borraNan: \n",
    "            df.dropna(inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def ocpBb(self, df, periodo=20, desvios=2, borraNan=False, col='Close'):\n",
    "        \"\"\"Bollinger Bands - from your indicators library\"\"\"\n",
    "        df[f'bs{periodo}'] = df[col].rolling(periodo).mean()\n",
    "        vola = df[col].rolling(periodo).std()\n",
    "        df['bInf'] = df[f'bs{periodo}'] - desvios * vola\n",
    "        df['bSup'] = df[f'bs{periodo}'] + desvios * vola\n",
    "        if borraNan: \n",
    "            df.dropna(inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def ocpAtr(self, df, periodo=14, borraNan=False):\n",
    "        \"\"\"ATR - from your indicators library\"\"\"\n",
    "        df['atrHL'] = abs(df.High - df.Low)\n",
    "        df['atrHC'] = abs(df.High - df.Close.shift())\n",
    "        df['atrLC'] = abs(df.Low - df.Close.shift())\n",
    "        df['atrMax'] = df[['atrHL', 'atrHC', 'atrLC']].max(axis=1)\n",
    "        df[f'atr{periodo}'] = df.atrMax.ewm(span=periodo, adjust=False).mean()\n",
    "        df['atrMaxP'] = df[['atrHL', 'atrHC', 'atrLC']].max(axis=1) / df.Close\n",
    "        df[f'atr%{periodo}'] = df.atrMaxP.ewm(span=periodo, adjust=False).mean()\n",
    "        df.drop(['atrHL', 'atrHC', 'atrLC', 'atrMax', 'atrMaxP'], axis=1, inplace=True)\n",
    "        if borraNan: \n",
    "            df.dropna(inplace=True)\n",
    "        return df\n",
    "\n",
    "# Initialize the indicator factory\n",
    "indicator_factory = TechnicalIndicatorFactory()\n",
    "print(\"ğŸ­ Technical Indicator Factory initialized\")\n",
    "print(f\"ğŸ“Š Available indicators: {list(indicator_factory.indicator_registry.keys())}\")\n",
    "print(f\"ğŸ“‚ Categories: {list(indicator_factory.get_indicator_categories().keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f160cb2",
   "metadata": {},
   "source": [
    "# PHASE 4: DATA SPLITTING (IN-SAMPLE VS OUT-SAMPLE)\n",
    "\n",
    "## Intelligent Data Partitioning\n",
    "\n",
    "Building on your framework's validation methodology, we'll implement sophisticated data splitting that ensures:\n",
    "\n",
    "### Key Principles:\n",
    "- **Temporal Consistency**: No future data leakage\n",
    "- **Sufficient Sample Size**: Adequate data for training and testing\n",
    "- **Market Regime Coverage**: Include different market conditions\n",
    "- **Rolling Validation**: Walk-forward and cross-validation ready\n",
    "\n",
    "### Splitting Strategies:\n",
    "1. **Simple Split**: Traditional train/test split\n",
    "2. **Walk Forward**: Expanding window validation  \n",
    "3. **Rolling Window**: Fixed-size training windows\n",
    "4. **Custom Periods**: User-defined date ranges\n",
    "5. **Monte Carlo**: Multiple random splits for robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntelligentDataSplitter:\n",
    "    \"\"\"\n",
    "    Advanced data splitting for trading strategy validation\n",
    "    Based on your framework's validation methodology\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.split_configs = {\n",
    "            'simple': {'train_pct': 0.7, 'description': 'Simple 70/30 split'},\n",
    "            'strict': {'train_pct': 0.6, 'description': 'Conservative 60/40 split'},\n",
    "            'aggressive': {'train_pct': 0.8, 'description': 'Aggressive 80/20 split'}\n",
    "        }\n",
    "    \n",
    "    def simple_split(self, data, train_pct=0.7, min_test_days=252):\n",
    "        \"\"\"\n",
    "        Simple temporal split ensuring no future data leakage\n",
    "        \"\"\"\n",
    "        total_days = len(data)\n",
    "        \n",
    "        # Ensure minimum test period (1 trading year)\n",
    "        min_train_days = max(int(total_days * train_pct), total_days - min_test_days)\n",
    "        split_point = min(min_train_days, int(total_days * train_pct))\n",
    "        \n",
    "        train_data = data.iloc[:split_point].copy()\n",
    "        test_data = data.iloc[split_point:].copy()\n",
    "        \n",
    "        split_info = {\n",
    "            'method': 'simple_split',\n",
    "            'train_start': train_data.index[0],\n",
    "            'train_end': train_data.index[-1],\n",
    "            'test_start': test_data.index[0],\n",
    "            'test_end': test_data.index[-1],\n",
    "            'train_days': len(train_data),\n",
    "            'test_days': len(test_data),\n",
    "            'train_pct': len(train_data) / total_days,\n",
    "            'test_pct': len(test_data) / total_days\n",
    "        }\n",
    "        \n",
    "        return train_data, test_data, split_info\n",
    "    \n",
    "    def walk_forward_splits(self, data, initial_train_pct=0.5, num_splits=5):\n",
    "        \"\"\"\n",
    "        Walk-forward validation splits (expanding window)\n",
    "        Mimics your framework's walk-forward methodology\n",
    "        \"\"\"\n",
    "        total_days = len(data)\n",
    "        initial_train_size = int(total_days * initial_train_pct)\n",
    "        \n",
    "        # Calculate step size for remaining data\n",
    "        remaining_days = total_days - initial_train_size\n",
    "        step_size = remaining_days // num_splits\n",
    "        \n",
    "        splits = []\n",
    "        \n",
    "        for i in range(num_splits):\n",
    "            train_end = initial_train_size + (i * step_size)\n",
    "            test_start = train_end\n",
    "            test_end = min(train_end + step_size, total_days)\n",
    "            \n",
    "            if test_end <= test_start:\n",
    "                break\n",
    "                \n",
    "            train_data = data.iloc[:train_end].copy()\n",
    "            test_data = data.iloc[test_start:test_end].copy()\n",
    "            \n",
    "            split_info = {\n",
    "                'split_number': i + 1,\n",
    "                'train_start': train_data.index[0],\n",
    "                'train_end': train_data.index[-1], \n",
    "                'test_start': test_data.index[0],\n",
    "                'test_end': test_data.index[-1],\n",
    "                'train_days': len(train_data),\n",
    "                'test_days': len(test_data)\n",
    "            }\n",
    "            \n",
    "            splits.append((train_data, test_data, split_info))\n",
    "        \n",
    "        return splits\n",
    "    \n",
    "    def rolling_window_splits(self, data, train_window=252*2, test_window=63, step_size=21):\n",
    "        \"\"\"\n",
    "        Rolling window validation (fixed-size windows)\n",
    "        \"\"\"\n",
    "        splits = []\n",
    "        start_idx = 0\n",
    "        \n",
    "        while start_idx + train_window + test_window <= len(data):\n",
    "            train_end = start_idx + train_window\n",
    "            test_end = train_end + test_window\n",
    "            \n",
    "            train_data = data.iloc[start_idx:train_end].copy()\n",
    "            test_data = data.iloc[train_end:test_end].copy()\n",
    "            \n",
    "            split_info = {\n",
    "                'method': 'rolling_window',\n",
    "                'split_number': len(splits) + 1,\n",
    "                'train_start': train_data.index[0],\n",
    "                'train_end': train_data.index[-1],\n",
    "                'test_start': test_data.index[0], \n",
    "                'test_end': test_data.index[-1],\n",
    "                'train_days': len(train_data),\n",
    "                'test_days': len(test_data)\n",
    "            }\n",
    "            \n",
    "            splits.append((train_data, test_data, split_info))\n",
    "            start_idx += step_size\n",
    "        \n",
    "        return splits\n",
    "    \n",
    "    def custom_date_split(self, data, split_date):\n",
    "        \"\"\"\n",
    "        Split data at specific date\n",
    "        \"\"\"\n",
    "        split_date = pd.to_datetime(split_date)\n",
    "        \n",
    "        train_data = data[data.index < split_date].copy()\n",
    "        test_data = data[data.index >= split_date].copy()\n",
    "        \n",
    "        split_info = {\n",
    "            'method': 'custom_date',\n",
    "            'split_date': split_date,\n",
    "            'train_start': train_data.index[0],\n",
    "            'train_end': train_data.index[-1],\n",
    "            'test_start': test_data.index[0],\n",
    "            'test_end': test_data.index[-1],\n",
    "            'train_days': len(train_data),\n",
    "            'test_days': len(test_data)\n",
    "        }\n",
    "        \n",
    "        return train_data, test_data, split_info\n",
    "    \n",
    "    def validate_split(self, train_data, test_data, min_train_days=252, min_test_days=63):\n",
    "        \"\"\"\n",
    "        Validate that splits meet minimum requirements\n",
    "        \"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        if len(train_data) < min_train_days:\n",
    "            issues.append(f\"Training data too small: {len(train_data)} < {min_train_days}\")\n",
    "            \n",
    "        if len(test_data) < min_test_days:\n",
    "            issues.append(f\"Test data too small: {len(test_data)} < {min_test_days}\")\n",
    "            \n",
    "        if train_data.index[-1] >= test_data.index[0]:\n",
    "            issues.append(\"Data leakage: training period overlaps with test period\")\n",
    "            \n",
    "        # Check for gaps\n",
    "        gap_days = (test_data.index[0] - train_data.index[-1]).days\n",
    "        if gap_days > 5:  # Allow for weekends\n",
    "            issues.append(f\"Large gap between train and test: {gap_days} days\")\n",
    "        \n",
    "        return len(issues) == 0, issues\n",
    "    \n",
    "    def analyze_market_regimes(self, data, split_info):\n",
    "        \"\"\"\n",
    "        Analyze market conditions in train vs test periods\n",
    "        \"\"\"\n",
    "        train_start, train_end = split_info['train_start'], split_info['train_end']\n",
    "        test_start, test_end = split_info['test_start'], split_info['test_end']\n",
    "        \n",
    "        train_returns = data.loc[train_start:train_end, 'Close'].pct_change().dropna()\n",
    "        test_returns = data.loc[test_start:test_end, 'Close'].pct_change().dropna()\n",
    "        \n",
    "        analysis = {\n",
    "            'train_metrics': {\n",
    "                'mean_return': train_returns.mean() * 252,  # Annualized\n",
    "                'volatility': train_returns.std() * np.sqrt(252),\n",
    "                'sharpe': (train_returns.mean() / train_returns.std()) * np.sqrt(252),\n",
    "                'max_drawdown': self._calculate_max_drawdown(train_returns)\n",
    "            },\n",
    "            'test_metrics': {\n",
    "                'mean_return': test_returns.mean() * 252,\n",
    "                'volatility': test_returns.std() * np.sqrt(252), \n",
    "                'sharpe': (test_returns.mean() / test_returns.std()) * np.sqrt(252),\n",
    "                'max_drawdown': self._calculate_max_drawdown(test_returns)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _calculate_max_drawdown(self, returns):\n",
    "        \"\"\"Calculate maximum drawdown from returns series\"\"\"\n",
    "        cumulative = (1 + returns).cumprod()\n",
    "        rolling_max = cumulative.expanding().max()\n",
    "        drawdown = (cumulative / rolling_max - 1)\n",
    "        return drawdown.min()\n",
    "\n",
    "# Initialize the data splitter\n",
    "data_splitter = IntelligentDataSplitter()\n",
    "print(\"âœ‚ï¸  Intelligent Data Splitter initialized\")\n",
    "print(\"ğŸ“Š Ready for temporal validation with no future leakage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd710c",
   "metadata": {},
   "source": [
    "# PHASE 5: OPENAI SDK INTEGRATION FOR AGENT LOGIC\n",
    "\n",
    "## AI-Powered Trading Agent\n",
    "\n",
    "This is where we bring intelligence to your professional framework! The AI agent will:\n",
    "\n",
    "### Core Capabilities:\n",
    "- **Market Analysis**: Interpret technical indicators intelligently\n",
    "- **Strategy Development**: Create and refine trading rules\n",
    "- **Risk Assessment**: Evaluate position sizing and risk management\n",
    "- **Performance Learning**: Adapt based on backtesting results\n",
    "- **Multi-Asset Trading**: Handle different asset classes\n",
    "\n",
    "### Agent Architecture:\n",
    "1. **Context Understanding**: Interpret market data and indicators\n",
    "2. **Decision Making**: Generate trading signals with reasoning\n",
    "3. **Risk Management**: Apply proper position sizing and stops\n",
    "4. **Performance Analysis**: Learn from historical results\n",
    "5. **Strategy Evolution**: Improve strategies over time\n",
    "\n",
    "### Integration Points:\n",
    "- Your **Technical Indicators** â†’ AI analysis\n",
    "- Your **Backtesting Framework** â†’ AI validation\n",
    "- Your **Risk Management** â†’ AI position sizing\n",
    "- Your **Validation Methods** â†’ AI learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82eefa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Configuration\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "class AITradingAgent:\n",
    "    \"\"\"\n",
    "    Intelligent trading agent powered by OpenAI\n",
    "    Integrates with your professional backtesting framework\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key=None, model=\"gpt-4\", temperature=0.1):\n",
    "        \"\"\"\n",
    "        Initialize the AI trading agent\n",
    "        \n",
    "        Args:\n",
    "            api_key: OpenAI API key (or set OPENAI_API_KEY environment variable)\n",
    "            model: OpenAI model to use (gpt-4, gpt-3.5-turbo, etc.)\n",
    "            temperature: Response randomness (0.0 = deterministic, 1.0 = creative)\n",
    "        \"\"\"\n",
    "        # Set up OpenAI client\n",
    "        if api_key:\n",
    "            os.environ['OPENAI_API_KEY'] = api_key\n",
    "        \n",
    "        try:\n",
    "            self.client = OpenAI()\n",
    "            self.model = model\n",
    "            self.temperature = temperature\n",
    "            print(\"ğŸ¤– AI Trading Agent initialized successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to initialize OpenAI client: {e}\")\n",
    "            print(\"ğŸ’¡ Please set your OPENAI_API_KEY environment variable\")\n",
    "            raise\n",
    "        \n",
    "        # Initialize components\n",
    "        self.system_prompts = self._create_system_prompts()\n",
    "        self.trading_context = {}\n",
    "        self.decision_history = []\n",
    "        \n",
    "    def _create_system_prompts(self):\n",
    "        \"\"\"Create specialized system prompts for different trading tasks\"\"\"\n",
    "        return {\n",
    "            'market_analysis': \"\"\"You are an expert quantitative trading analyst with deep knowledge of technical analysis and market dynamics. \n",
    "\n",
    "Your role is to analyze market data and technical indicators to provide insights about:\n",
    "- Current market trends and momentum\n",
    "- Support and resistance levels\n",
    "- Volatility conditions\n",
    "- Risk factors\n",
    "- Trading opportunities\n",
    "\n",
    "Always provide clear, actionable analysis based on the data provided. Be specific about indicator readings and their implications.\"\"\",\n",
    "\n",
    "            'strategy_development': \"\"\"You are a systematic trading strategy developer with expertise in quantitative finance.\n",
    "\n",
    "Your role is to create robust trading strategies that:\n",
    "- Use technical indicators effectively\n",
    "- Include proper risk management\n",
    "- Have clear entry and exit rules\n",
    "- Can be backtested systematically\n",
    "- Are suitable for the given market conditions\n",
    "\n",
    "Focus on strategies that are logical, testable, and have edge in the markets.\"\"\",\n",
    "\n",
    "            'risk_management': \"\"\"You are a risk management specialist for systematic trading.\n",
    "\n",
    "Your role is to assess and manage trading risk by:\n",
    "- Determining appropriate position sizes\n",
    "- Setting stop losses and take profits\n",
    "- Evaluating portfolio risk\n",
    "- Calculating risk-adjusted returns\n",
    "- Preventing catastrophic losses\n",
    "\n",
    "Always prioritize capital preservation while seeking consistent returns.\"\"\",\n",
    "\n",
    "            'performance_analysis': \"\"\"You are a trading performance analyst specializing in strategy evaluation.\n",
    "\n",
    "Your role is to analyze trading results and provide insights on:\n",
    "- Strategy performance metrics\n",
    "- Areas for improvement\n",
    "- Risk-adjusted performance\n",
    "- Consistency of returns\n",
    "- Strategy robustness across different market conditions\n",
    "\n",
    "Provide specific, actionable recommendations for strategy enhancement.\"\"\"\n",
    "        }\n",
    "    \n",
    "    def analyze_market_data(self, data, indicators=None, context=\"\"):\n",
    "        \"\"\"\n",
    "        Analyze market data and technical indicators\n",
    "        \"\"\"\n",
    "        # Prepare market data summary\n",
    "        recent_data = data.tail(20)  # Last 20 periods\n",
    "        \n",
    "        market_summary = {\n",
    "            'current_price': recent_data['Close'].iloc[-1],\n",
    "            'price_change_1d': recent_data['Close'].pct_change().iloc[-1] * 100,\n",
    "            'price_change_5d': ((recent_data['Close'].iloc[-1] / recent_data['Close'].iloc[-5]) - 1) * 100,\n",
    "            'volatility_20d': recent_data['Close'].pct_change().std() * np.sqrt(252) * 100,\n",
    "            'volume_trend': 'increasing' if recent_data['Volume'].iloc[-1] > recent_data['Volume'].iloc[-5] else 'decreasing'\n",
    "        }\n",
    "        \n",
    "        # Prepare indicator summary\n",
    "        indicator_summary = {}\n",
    "        if indicators:\n",
    "            for col in data.columns:\n",
    "                if any(ind in col.lower() for ind in ['sma', 'ema', 'rsi', 'macd', 'bb']):\n",
    "                    if col in data.columns:\n",
    "                        indicator_summary[col] = recent_data[col].iloc[-1]\n",
    "        \n",
    "        # Create analysis prompt\n",
    "        prompt = f\"\"\"\n",
    "        Analyze the following market data and technical indicators:\n",
    "\n",
    "        Market Summary:\n",
    "        - Current Price: ${market_summary['current_price']:.2f}\n",
    "        - 1-Day Change: {market_summary['price_change_1d']:.2f}%\n",
    "        - 5-Day Change: {market_summary['price_change_5d']:.2f}%\n",
    "        - 20-Day Volatility: {market_summary['volatility_20d']:.2f}%\n",
    "        - Volume Trend: {market_summary['volume_trend']}\n",
    "\n",
    "        Technical Indicators:\n",
    "        {json.dumps(indicator_summary, indent=2)}\n",
    "\n",
    "        Additional Context: {context}\n",
    "\n",
    "        Please provide:\n",
    "        1. Current market trend assessment\n",
    "        2. Key support and resistance levels\n",
    "        3. Momentum and volatility analysis\n",
    "        4. Risk factors to consider\n",
    "        5. Overall market outlook (bullish/bearish/neutral)\n",
    "\n",
    "        Keep your analysis concise but comprehensive.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self.system_prompts['market_analysis']},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=1000\n",
    "            )\n",
    "            \n",
    "            analysis = response.choices[0].message.content\n",
    "            \n",
    "            # Store in context\n",
    "            self.trading_context['last_analysis'] = {\n",
    "                'timestamp': datetime.now(),\n",
    "                'analysis': analysis,\n",
    "                'market_data': market_summary,\n",
    "                'indicators': indicator_summary\n",
    "            }\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error in market analysis: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_trading_strategy(self, market_analysis, available_indicators, objectives=\"\"):\n",
    "        \"\"\"\n",
    "        Generate a trading strategy based on market analysis\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Based on the following market analysis and available technical indicators, develop a systematic trading strategy:\n",
    "\n",
    "        Market Analysis:\n",
    "        {market_analysis}\n",
    "\n",
    "        Available Indicators:\n",
    "        {', '.join(available_indicators)}\n",
    "\n",
    "        Strategy Objectives:\n",
    "        {objectives if objectives else \"Generate consistent returns with controlled risk\"}\n",
    "\n",
    "        Please provide a complete trading strategy including:\n",
    "\n",
    "        1. ENTRY RULES:\n",
    "           - Specific conditions for entering long positions\n",
    "           - Specific conditions for entering short positions\n",
    "           - Required indicator combinations\n",
    "\n",
    "        2. EXIT RULES:\n",
    "           - Take profit conditions\n",
    "           - Stop loss conditions  \n",
    "           - Trailing stop rules if applicable\n",
    "\n",
    "        3. POSITION SIZING:\n",
    "           - How to determine position size\n",
    "           - Maximum position limits\n",
    "           - Risk per trade guidelines\n",
    "\n",
    "        4. RISK MANAGEMENT:\n",
    "           - Maximum drawdown limits\n",
    "           - Correlation limits\n",
    "           - Portfolio heat guidelines\n",
    "\n",
    "        5. IMPLEMENTATION:\n",
    "           - Code-ready indicator combinations\n",
    "           - Specific parameter values\n",
    "           - Execution logic\n",
    "\n",
    "        Make the strategy specific, testable, and suitable for systematic backtesting.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self.system_prompts['strategy_development']},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=2000\n",
    "            )\n",
    "            \n",
    "            strategy = response.choices[0].message.content\n",
    "            \n",
    "            # Store strategy\n",
    "            self.trading_context['current_strategy'] = {\n",
    "                'timestamp': datetime.now(),\n",
    "                'strategy': strategy,\n",
    "                'objectives': objectives\n",
    "            }\n",
    "            \n",
    "            return strategy\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error generating strategy: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def make_trading_decision(self, current_data, indicators, strategy_context=\"\"):\n",
    "        \"\"\"\n",
    "        Make a specific trading decision (buy/sell/hold)\n",
    "        \"\"\"\n",
    "        # Get current market state\n",
    "        current_price = current_data['Close'].iloc[-1]\n",
    "        \n",
    "        # Prepare indicator readings\n",
    "        indicator_readings = {}\n",
    "        for col in current_data.columns:\n",
    "            if col not in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "                indicator_readings[col] = current_data[col].iloc[-1]\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Make a trading decision based on current market conditions:\n",
    "\n",
    "        Current Price: ${current_price:.2f}\n",
    "        \n",
    "        Current Indicator Readings:\n",
    "        {json.dumps(indicator_readings, indent=2)}\n",
    "\n",
    "        Strategy Context:\n",
    "        {strategy_context}\n",
    "\n",
    "        Based on this information, provide:\n",
    "\n",
    "        1. DECISION: BUY, SELL, or HOLD\n",
    "        2. CONFIDENCE: High, Medium, or Low\n",
    "        3. REASONING: Explain your decision based on the indicators\n",
    "        4. POSITION_SIZE: Suggest position size (1-10 scale)\n",
    "        5. STOP_LOSS: Suggested stop loss level if applicable\n",
    "        6. TAKE_PROFIT: Suggested take profit level if applicable\n",
    "        7. RISK_FACTORS: Key risks to monitor\n",
    "\n",
    "        Format your response as JSON for easy parsing.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a systematic trading decision maker. Always respond in valid JSON format.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=800\n",
    "            )\n",
    "            \n",
    "            decision_text = response.choices[0].message.content\n",
    "            \n",
    "            # Try to parse as JSON\n",
    "            try:\n",
    "                decision = json.loads(decision_text)\n",
    "            except:\n",
    "                # Fallback to text parsing if JSON fails\n",
    "                decision = {\n",
    "                    'decision': 'HOLD',\n",
    "                    'confidence': 'Low',\n",
    "                    'reasoning': decision_text,\n",
    "                    'position_size': 1,\n",
    "                    'risk_factors': ['JSON parsing failed']\n",
    "                }\n",
    "            \n",
    "            # Store decision\n",
    "            decision_record = {\n",
    "                'timestamp': datetime.now(),\n",
    "                'price': current_price,\n",
    "                'decision': decision,\n",
    "                'indicators': indicator_readings\n",
    "            }\n",
    "            \n",
    "            self.decision_history.append(decision_record)\n",
    "            \n",
    "            return decision\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error making trading decision: {e}\")\n",
    "            return {'decision': 'HOLD', 'confidence': 'Low', 'reasoning': f'Error: {e}'}\n",
    "\n",
    "# Example initialization (you'll need to set your API key)\n",
    "print(\"ğŸ”§ OpenAI Trading Agent class ready\")\n",
    "print(\"ğŸ’¡ To use: agent = AITradingAgent(api_key='your-api-key')\")\n",
    "\n",
    "# Uncomment and add your API key to initialize:\n",
    "# agent = AITradingAgent(api_key=\"your-openai-api-key-here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc121f",
   "metadata": {},
   "source": [
    "# PHASE 6: BACKTESTING FRAMEWORK INTEGRATION\n",
    "\n",
    "## Professional-Grade Backtesting\n",
    "\n",
    "Your backtesting framework is exceptional! We'll integrate it seamlessly with the AI agent:\n",
    "\n",
    "### Framework Integration Points:\n",
    "- **Signal Generation**: AI decisions â†’ Trading signals\n",
    "- **Position Management**: AI position sizing â†’ Framework execution\n",
    "- **Risk Controls**: AI risk assessment â†’ Framework safeguards\n",
    "- **Performance Analytics**: Framework metrics â†’ AI learning\n",
    "- **Validation Methods**: All your validation techniques\n",
    "\n",
    "### Key Components to Integrate:\n",
    "1. **dameSistema()**: Convert AI decisions to signals\n",
    "2. **damePosition()**: Handle position state management\n",
    "3. **dameSalidaPnl()**: Calculate P&L with SL/TP\n",
    "4. **calculaCurvas()**: Performance curve generation\n",
    "5. **Validation Suite**: Walk-forward, Monte Carlo, etc.\n",
    "\n",
    "### Enhanced Features:\n",
    "- **Real-time Decision Making**: AI agent provides live signals\n",
    "- **Dynamic Parameter Tuning**: AI optimizes parameters\n",
    "- **Multi-Strategy Management**: Run multiple AI strategies\n",
    "- **Risk-Adjusted Performance**: AI learns from risk metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63336da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BacktestingIntegrator:\n",
    "    \"\"\"Bridges AI agent decisions with your professional backtesting framework\"\"\"\n",
    "    \n",
    "    def __init__(self, ai_agent: AITradingAgent):\n",
    "        self.ai_agent = ai_agent\n",
    "        self.signals_history = []\n",
    "        self.positions_history = []\n",
    "        self.decisions_history = []\n",
    "        \n",
    "    def convert_ai_decisions_to_signals(self, data, ai_decision):\n",
    "        \"\"\"Convert AI decisions to your framework's signal format\"\"\"\n",
    "        signals = pd.Series(0, index=data.index)\n",
    "        \n",
    "        if ai_decision['action'] == 'BUY':\n",
    "            signals.iloc[-1] = 1  # Long signal\n",
    "        elif ai_decision['action'] == 'SELL':\n",
    "            signals.iloc[-1] = -1  # Short signal\n",
    "        else:  # HOLD\n",
    "            signals.iloc[-1] = 0  # No signal\n",
    "            \n",
    "        # Store decision metadata for learning\n",
    "        self.decisions_history.append({\n",
    "            'timestamp': data.index[-1],\n",
    "            'decision': ai_decision,\n",
    "            'market_conditions': self._analyze_market_state(data)\n",
    "        })\n",
    "        \n",
    "        return signals\n",
    "    \n",
    "    def enhanced_dameSistema(self, data, columna='close', **params):\n",
    "        \"\"\"Enhanced version of your dameSistema with AI integration\"\"\"\n",
    "        # Get AI agent's market analysis and strategy\n",
    "        market_analysis = self.ai_agent.analyze_market_conditions(data)\n",
    "        strategy_params = self.ai_agent.develop_strategy(data, market_analysis)\n",
    "        \n",
    "        # Generate AI-driven signals\n",
    "        ai_decision = self.ai_agent.make_trading_decision(data, market_analysis, strategy_params)\n",
    "        signals = self.convert_ai_decisions_to_signals(data, ai_decision)\n",
    "        \n",
    "        # Apply your position sizing and risk management\n",
    "        positions = self._calculate_positions(signals, data, ai_decision['confidence'])\n",
    "        \n",
    "        return {\n",
    "            'signals': signals,\n",
    "            'positions': positions,\n",
    "            'ai_decision': ai_decision,\n",
    "            'market_analysis': market_analysis,\n",
    "            'strategy_params': strategy_params\n",
    "        }\n",
    "    \n",
    "    def _calculate_positions(self, signals, data, confidence):\n",
    "        \"\"\"Calculate position sizes based on AI confidence and risk management\"\"\"\n",
    "        positions = pd.Series(0.0, index=data.index)\n",
    "        base_position_size = 0.1  # 10% base allocation\n",
    "        \n",
    "        # Adjust position size based on AI confidence\n",
    "        confidence_multiplier = min(confidence / 0.8, 1.5)  # Max 1.5x for high confidence\n",
    "        \n",
    "        for i in range(len(signals)):\n",
    "            if signals.iloc[i] != 0:\n",
    "                position_size = base_position_size * confidence_multiplier\n",
    "                positions.iloc[i] = signals.iloc[i] * position_size\n",
    "                \n",
    "        return positions\n",
    "    \n",
    "    def run_ai_enhanced_backtest(self, data, initial_capital=100000):\n",
    "        \"\"\"Run comprehensive backtest with AI integration and your validation methods\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Generate enhanced signals using AI\n",
    "        system_output = self.enhanced_dameSistema(data)\n",
    "        \n",
    "        # Apply your existing backtesting logic\n",
    "        pnl_data = self._calculate_pnl_with_framework(\n",
    "            data, \n",
    "            system_output['signals'], \n",
    "            system_output['positions']\n",
    "        )\n",
    "        \n",
    "        # Calculate performance metrics using your framework\n",
    "        performance_metrics = self._calculate_comprehensive_metrics(pnl_data, initial_capital)\n",
    "        \n",
    "        # Store results for AI learning\n",
    "        results = {\n",
    "            'pnl_data': pnl_data,\n",
    "            'performance_metrics': performance_metrics,\n",
    "            'ai_decisions': self.decisions_history,\n",
    "            'signals_summary': self._summarize_signals(system_output['signals']),\n",
    "            'market_analysis': system_output['market_analysis']\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _calculate_pnl_with_framework(self, data, signals, positions):\n",
    "        \"\"\"Use your existing P&L calculation logic\"\"\"\n",
    "        # This would integrate with your dameSalidaPnl function\n",
    "        # and other existing P&L calculation methods\n",
    "        \n",
    "        pnl_series = pd.Series(0.0, index=data.index)\n",
    "        cumulative_pnl = 0\n",
    "        current_position = 0\n",
    "        entry_price = 0\n",
    "        \n",
    "        for i in range(1, len(data)):\n",
    "            price = data['close'].iloc[i]\n",
    "            signal = signals.iloc[i]\n",
    "            \n",
    "            # Entry logic\n",
    "            if signal != 0 and current_position == 0:\n",
    "                current_position = signal\n",
    "                entry_price = price\n",
    "                \n",
    "            # Exit logic (simplified - your framework has more sophisticated exits)\n",
    "            elif current_position != 0:\n",
    "                if signal == -current_position or i == len(data) - 1:\n",
    "                    # Calculate P&L\n",
    "                    trade_pnl = current_position * (price - entry_price)\n",
    "                    cumulative_pnl += trade_pnl\n",
    "                    current_position = 0\n",
    "                    \n",
    "            pnl_series.iloc[i] = cumulative_pnl\n",
    "            \n",
    "        return pnl_series\n",
    "    \n",
    "    def _analyze_market_state(self, data):\n",
    "        \"\"\"Analyze current market conditions for AI learning\"\"\"\n",
    "        recent_data = data.tail(20)\n",
    "        \n",
    "        return {\n",
    "            'volatility': recent_data['close'].std(),\n",
    "            'trend': (recent_data['close'].iloc[-1] - recent_data['close'].iloc[0]) / recent_data['close'].iloc[0],\n",
    "            'volume_trend': recent_data['volume'].rolling(5).mean().iloc[-1] if 'volume' in recent_data.columns else None\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f4449",
   "metadata": {},
   "source": [
    "# PHASE 7: AGENT DECISION MAKING SYSTEM\n",
    "\n",
    "## Intelligent Decision Architecture\n",
    "\n",
    "Building on your solid framework, we'll create a sophisticated AI decision-making system:\n",
    "\n",
    "### Core Decision Components:\n",
    "1. **Multi-Timeframe Analysis**: 1min, 5min, 15min, 1H, 1D perspectives\n",
    "2. **Risk-Reward Assessment**: Dynamic R:R ratios based on market conditions\n",
    "3. **Confidence Scoring**: AI evaluates its own decision quality\n",
    "4. **Adaptive Strategy Selection**: Choose best strategy for current market\n",
    "5. **Portfolio Optimization**: Optimal position sizing and diversification\n",
    "\n",
    "### Decision Flow:\n",
    "```\n",
    "Market Data â†’ Technical Analysis â†’ Fundamental Factors â†’ Risk Assessment â†’ Decision + Confidence\n",
    "```\n",
    "\n",
    "### Integration with Your Framework:\n",
    "- **RSI2 Strategy**: AI enhances with dynamic parameters\n",
    "- **Multiple Validation**: AI decisions tested with your validation suite\n",
    "- **Risk Management**: AI respects your position sizing and stop-loss rules\n",
    "- **Performance Feedback**: AI learns from your comprehensive metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedDecisionEngine:\n",
    "    \"\"\"Sophisticated AI decision-making system leveraging your framework\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_client, indicator_factory: TechnicalIndicatorFactory):\n",
    "        self.openai_client = openai_client\n",
    "        self.indicator_factory = indicator_factory\n",
    "        self.decision_history = []\n",
    "        self.performance_tracker = {}\n",
    "        \n",
    "    def make_comprehensive_decision(self, data, symbol='SPY'):\n",
    "        \"\"\"Advanced decision making with multi-factor analysis\"\"\"\n",
    "        \n",
    "        # 1. Multi-timeframe technical analysis\n",
    "        technical_signals = self._analyze_multiple_timeframes(data)\n",
    "        \n",
    "        # 2. Market regime detection\n",
    "        market_regime = self._detect_market_regime(data)\n",
    "        \n",
    "        # 3. Risk assessment\n",
    "        risk_metrics = self._assess_current_risk(data)\n",
    "        \n",
    "        # 4. Strategy selection based on conditions\n",
    "        optimal_strategy = self._select_optimal_strategy(market_regime, risk_metrics)\n",
    "        \n",
    "        # 5. AI-powered final decision\n",
    "        final_decision = self._ai_decision_synthesis(\n",
    "            technical_signals, market_regime, risk_metrics, optimal_strategy, data\n",
    "        )\n",
    "        \n",
    "        # 6. Track decision for learning\n",
    "        self._track_decision(final_decision, data)\n",
    "        \n",
    "        return final_decision\n",
    "    \n",
    "    def _analyze_multiple_timeframes(self, data):\n",
    "        \"\"\"Analyze signals across multiple timeframes\"\"\"\n",
    "        timeframes = {\n",
    "            'short_term': data.tail(20),    # Short-term: last 20 bars\n",
    "            'medium_term': data.tail(50),   # Medium-term: last 50 bars  \n",
    "            'long_term': data.tail(200)     # Long-term: last 200 bars\n",
    "        }\n",
    "        \n",
    "        signals = {}\n",
    "        for tf_name, tf_data in timeframes.items():\n",
    "            if len(tf_data) > 10:  # Ensure enough data\n",
    "                signals[tf_name] = {\n",
    "                    'rsi': self.indicator_factory.rsi(tf_data['close']).iloc[-1],\n",
    "                    'macd_signal': self._get_macd_signal(tf_data),\n",
    "                    'bb_position': self._get_bollinger_position(tf_data),\n",
    "                    'trend': self._get_trend_direction(tf_data),\n",
    "                    'volume_trend': self._get_volume_trend(tf_data)\n",
    "                }\n",
    "        \n",
    "        return signals\n",
    "    \n",
    "    def _detect_market_regime(self, data):\n",
    "        \"\"\"Detect current market regime (trending, ranging, volatile)\"\"\"\n",
    "        recent_data = data.tail(50)\n",
    "        \n",
    "        # Volatility analysis\n",
    "        volatility = recent_data['close'].rolling(20).std().iloc[-1]\n",
    "        avg_volatility = recent_data['close'].rolling(20).std().mean()\n",
    "        \n",
    "        # Trend strength\n",
    "        trend_strength = abs(\n",
    "            (recent_data['close'].iloc[-1] - recent_data['close'].iloc[0]) / \n",
    "            recent_data['close'].iloc[0]\n",
    "        )\n",
    "        \n",
    "        # Range analysis\n",
    "        high_low_ratio = (recent_data['high'].max() - recent_data['low'].min()) / recent_data['close'].mean()\n",
    "        \n",
    "        if trend_strength > 0.05 and volatility < avg_volatility * 1.2:\n",
    "            return \"trending\"\n",
    "        elif volatility > avg_volatility * 1.5:\n",
    "            return \"volatile\"\n",
    "        else:\n",
    "            return \"ranging\"\n",
    "    \n",
    "    def _assess_current_risk(self, data):\n",
    "        \"\"\"Comprehensive risk assessment\"\"\"\n",
    "        recent_data = data.tail(30)\n",
    "        \n",
    "        # Calculate various risk metrics\n",
    "        volatility = recent_data['close'].pct_change().std() * np.sqrt(252)  # Annualized\n",
    "        drawdown = self._calculate_current_drawdown(recent_data)\n",
    "        correlation_risk = self._assess_correlation_risk(recent_data)\n",
    "        \n",
    "        # VaR estimation (simplified)\n",
    "        returns = recent_data['close'].pct_change().dropna()\n",
    "        var_95 = returns.quantile(0.05) if len(returns) > 5 else -0.02\n",
    "        \n",
    "        return {\n",
    "            'volatility': volatility,\n",
    "            'drawdown': drawdown,\n",
    "            'var_95': var_95,\n",
    "            'correlation_risk': correlation_risk,\n",
    "            'risk_score': self._calculate_composite_risk_score(volatility, drawdown, var_95)\n",
    "        }\n",
    "    \n",
    "    def _select_optimal_strategy(self, market_regime, risk_metrics):\n",
    "        \"\"\"Select best strategy based on market conditions\"\"\"\n",
    "        strategies = {\n",
    "            'trending': {\n",
    "                'name': 'Enhanced Momentum',\n",
    "                'params': {'rsi_oversold': 30, 'rsi_overbought': 70, 'trend_filter': True},\n",
    "                'risk_adjustment': 1.0\n",
    "            },\n",
    "            'ranging': {\n",
    "                'name': 'Mean Reversion Enhanced',\n",
    "                'params': {'rsi_oversold': 20, 'rsi_overbought': 80, 'trend_filter': False},\n",
    "                'risk_adjustment': 0.8\n",
    "            },\n",
    "            'volatile': {\n",
    "                'name': 'Conservative Breakout',\n",
    "                'params': {'rsi_oversold': 25, 'rsi_overbought': 75, 'volatility_filter': True},\n",
    "                'risk_adjustment': 0.6\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        base_strategy = strategies.get(market_regime, strategies['ranging'])\n",
    "        \n",
    "        # Adjust for risk\n",
    "        if risk_metrics['risk_score'] > 0.7:\n",
    "            base_strategy['risk_adjustment'] *= 0.7\n",
    "            \n",
    "        return base_strategy\n",
    "    \n",
    "    def _ai_decision_synthesis(self, technical_signals, market_regime, risk_metrics, strategy, data):\n",
    "        \"\"\"Use OpenAI to synthesize final decision\"\"\"\n",
    "        \n",
    "        # Prepare comprehensive prompt for AI\n",
    "        analysis_prompt = f\"\"\"\n",
    "        As an expert trading AI, analyze this market situation and make a trading decision:\n",
    "        \n",
    "        TECHNICAL SIGNALS:\n",
    "        {self._format_technical_signals(technical_signals)}\n",
    "        \n",
    "        MARKET REGIME: {market_regime}\n",
    "        \n",
    "        RISK METRICS:\n",
    "        - Volatility: {risk_metrics['volatility']:.3f}\n",
    "        - Current Drawdown: {risk_metrics['drawdown']:.3f}\n",
    "        - VaR (95%): {risk_metrics['var_95']:.3f}\n",
    "        - Risk Score: {risk_metrics['risk_score']:.3f}\n",
    "        \n",
    "        RECOMMENDED STRATEGY: {strategy['name']}\n",
    "        Strategy Parameters: {strategy['params']}\n",
    "        Risk Adjustment Factor: {strategy['risk_adjustment']}\n",
    "        \n",
    "        CURRENT PRICE: {data['close'].iloc[-1]:.2f}\n",
    "        \n",
    "        Based on this comprehensive analysis, provide your decision in this exact JSON format:\n",
    "        {{\n",
    "            \"action\": \"BUY|SELL|HOLD\",\n",
    "            \"confidence\": 0.0-1.0,\n",
    "            \"reasoning\": \"detailed explanation\",\n",
    "            \"position_size\": 0.0-1.0,\n",
    "            \"stop_loss\": price_level,\n",
    "            \"take_profit\": price_level,\n",
    "            \"expected_holding_period\": \"1-10 days\",\n",
    "            \"risk_reward_ratio\": ratio\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.openai_client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a professional quantitative trading AI with deep market expertise.\"},\n",
    "                    {\"role\": \"user\", \"content\": analysis_prompt}\n",
    "                ],\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            # Parse AI response\n",
    "            decision_text = response.choices[0].message.content\n",
    "            decision = self._parse_ai_decision(decision_text)\n",
    "            \n",
    "            # Apply risk adjustments\n",
    "            decision = self._apply_risk_adjustments(decision, risk_metrics, strategy)\n",
    "            \n",
    "            return decision\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"AI decision error: {e}\")\n",
    "            return self._fallback_decision(technical_signals, risk_metrics)\n",
    "    \n",
    "    def _apply_risk_adjustments(self, decision, risk_metrics, strategy):\n",
    "        \"\"\"Apply final risk adjustments to AI decision\"\"\"\n",
    "        # Adjust position size based on risk\n",
    "        risk_adjusted_size = decision['position_size'] * strategy['risk_adjustment']\n",
    "        \n",
    "        # Further reduce if high risk\n",
    "        if risk_metrics['risk_score'] > 0.8:\n",
    "            risk_adjusted_size *= 0.5\n",
    "            \n",
    "        decision['position_size'] = min(risk_adjusted_size, 0.2)  # Max 20% position\n",
    "        decision['risk_adjusted'] = True\n",
    "        decision['original_size'] = decision['position_size']\n",
    "        \n",
    "        return decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1bb131",
   "metadata": {},
   "source": [
    "# PHASE 8: PERFORMANCE VALIDATION AND METRICS\n",
    "\n",
    "## Professional-Grade Validation (Leveraging Your Framework)\n",
    "\n",
    "Your existing validation methods are industry-standard! We'll enhance them with AI-specific metrics:\n",
    "\n",
    "### Your Existing Validation Methods (Enhanced):\n",
    "1. **Walk Forward Analysis** â†’ AI parameter optimization\n",
    "2. **Monte Carlo Simulation** â†’ AI decision robustness testing  \n",
    "3. **Cross Validation** â†’ AI strategy generalization\n",
    "4. **Out-of-Sample Testing** â†’ AI overfitting prevention\n",
    "5. **Bootstrap Analysis** â†’ AI confidence intervals\n",
    "\n",
    "### New AI-Specific Metrics:\n",
    "- **Decision Accuracy**: How often AI predictions are correct\n",
    "- **Confidence Calibration**: Does AI confidence match actual performance?\n",
    "- **Adaptive Learning Rate**: How quickly AI improves\n",
    "- **Strategy Switching Efficiency**: AI's strategy selection performance\n",
    "- **Risk-Adjusted AI Alpha**: AI's contribution beyond market\n",
    "\n",
    "### Performance Dashboard:\n",
    "- Traditional metrics (Sharpe, Sortino, Max DD, Calmar)\n",
    "- AI-enhanced metrics (Confidence-weighted returns, Decision quality)\n",
    "- Comparative analysis (AI vs Base strategy vs Benchmark)\n",
    "- Real-time performance tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20108e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIValidationFramework:\n",
    "    \"\"\"Enhanced validation leveraging your existing professional framework\"\"\"\n",
    "    \n",
    "    def __init__(self, backtesting_integrator: BacktestingIntegrator):\n",
    "        self.backtesting_integrator = backtesting_integrator\n",
    "        self.validation_results = {}\n",
    "        \n",
    "    def comprehensive_validation_suite(self, data, symbols=['SPY'], validation_periods=10):\n",
    "        \"\"\"Run complete validation using your framework + AI enhancements\"\"\"\n",
    "        \n",
    "        results = {\n",
    "            'walk_forward': self.enhanced_walk_forward_analysis(data, validation_periods),\n",
    "            'monte_carlo': self.ai_monte_carlo_simulation(data, n_simulations=1000),\n",
    "            'cross_validation': self.ai_cross_validation(data, k_folds=5),\n",
    "            'out_of_sample': self.out_of_sample_validation(data, test_ratio=0.3),\n",
    "            'ai_specific_metrics': self.calculate_ai_metrics(data),\n",
    "            'performance_comparison': self.compare_ai_vs_baseline(data)\n",
    "        }\n",
    "        \n",
    "        # Generate comprehensive report\n",
    "        self.validation_results = results\n",
    "        return results\n",
    "    \n",
    "    def enhanced_walk_forward_analysis(self, data, periods=10):\n",
    "        \"\"\"Your walk-forward analysis enhanced with AI learning\"\"\"\n",
    "        period_length = len(data) // periods\n",
    "        results = []\n",
    "        \n",
    "        for i in range(periods):\n",
    "            start_idx = i * period_length\n",
    "            end_idx = start_idx + period_length\n",
    "            \n",
    "            # Training period\n",
    "            train_data = data.iloc[start_idx:end_idx]\n",
    "            \n",
    "            # Test period (next period)\n",
    "            if end_idx + period_length <= len(data):\n",
    "                test_data = data.iloc[end_idx:end_idx + period_length]\n",
    "                \n",
    "                # Train AI on this period\n",
    "                self.backtesting_integrator.ai_agent.learn_from_period(train_data)\n",
    "                \n",
    "                # Test on next period\n",
    "                period_results = self.backtesting_integrator.run_ai_enhanced_backtest(test_data)\n",
    "                \n",
    "                results.append({\n",
    "                    'period': i + 1,\n",
    "                    'train_start': train_data.index[0],\n",
    "                    'train_end': train_data.index[-1],\n",
    "                    'test_start': test_data.index[0],\n",
    "                    'test_end': test_data.index[-1],\n",
    "                    'performance_metrics': period_results['performance_metrics'],\n",
    "                    'ai_decisions_count': len(period_results['ai_decisions']),\n",
    "                    'avg_confidence': np.mean([d['decision']['confidence'] for d in period_results['ai_decisions']])\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'period_results': results,\n",
    "            'overall_metrics': self._calculate_walk_forward_summary(results),\n",
    "            'consistency_score': self._calculate_consistency_score(results)\n",
    "        }\n",
    "    \n",
    "    def ai_monte_carlo_simulation(self, data, n_simulations=1000):\n",
    "        \"\"\"Monte Carlo simulation with AI decision variability\"\"\"\n",
    "        simulation_results = []\n",
    "        \n",
    "        for sim in range(n_simulations):\n",
    "            # Add randomness to AI decisions (simulate market uncertainty)\n",
    "            modified_data = self._add_market_noise(data, noise_level=0.01)\n",
    "            \n",
    "            # Run backtest with modified data\n",
    "            sim_results = self.backtesting_integrator.run_ai_enhanced_backtest(modified_data)\n",
    "            \n",
    "            simulation_results.append({\n",
    "                'simulation': sim + 1,\n",
    "                'final_return': sim_results['performance_metrics']['total_return'],\n",
    "                'sharpe_ratio': sim_results['performance_metrics']['sharpe_ratio'],\n",
    "                'max_drawdown': sim_results['performance_metrics']['max_drawdown'],\n",
    "                'ai_decisions': len(sim_results['ai_decisions'])\n",
    "            })\n",
    "            \n",
    "            if sim % 100 == 0:\n",
    "                print(f\"Monte Carlo progress: {sim}/{n_simulations}\")\n",
    "        \n",
    "        return {\n",
    "            'simulations': simulation_results,\n",
    "            'confidence_intervals': self._calculate_confidence_intervals(simulation_results),\n",
    "            'risk_metrics': self._calculate_monte_carlo_risk_metrics(simulation_results),\n",
    "            'robustness_score': self._calculate_robustness_score(simulation_results)\n",
    "        }\n",
    "    \n",
    "    def calculate_ai_metrics(self, data):\n",
    "        \"\"\"Calculate AI-specific performance metrics\"\"\"\n",
    "        decisions = self.backtesting_integrator.decisions_history\n",
    "        \n",
    "        if not decisions:\n",
    "            return {\"error\": \"No AI decisions found. Run backtest first.\"}\n",
    "        \n",
    "        # Decision accuracy analysis\n",
    "        correct_decisions = 0\n",
    "        total_decisions = len(decisions)\n",
    "        confidence_scores = []\n",
    "        \n",
    "        for i, decision in enumerate(decisions):\n",
    "            confidence_scores.append(decision['decision']['confidence'])\n",
    "            \n",
    "            # Check if decision was profitable (simplified)\n",
    "            if i < len(decisions) - 1:\n",
    "                current_price = decision['market_conditions'].get('current_price', 0)\n",
    "                next_decision = decisions[i + 1]\n",
    "                next_price = next_decision['market_conditions'].get('current_price', 0)\n",
    "                \n",
    "                if decision['decision']['action'] == 'BUY' and next_price > current_price:\n",
    "                    correct_decisions += 1\n",
    "                elif decision['decision']['action'] == 'SELL' and next_price < current_price:\n",
    "                    correct_decisions += 1\n",
    "                elif decision['decision']['action'] == 'HOLD':\n",
    "                    correct_decisions += 0.5  # Neutral decision\n",
    "        \n",
    "        decision_accuracy = correct_decisions / total_decisions if total_decisions > 0 else 0\n",
    "        avg_confidence = np.mean(confidence_scores) if confidence_scores else 0\n",
    "        \n",
    "        # Confidence calibration\n",
    "        confidence_calibration = self._calculate_confidence_calibration(decisions)\n",
    "        \n",
    "        return {\n",
    "            'decision_accuracy': decision_accuracy,\n",
    "            'average_confidence': avg_confidence,\n",
    "            'confidence_calibration': confidence_calibration,\n",
    "            'total_decisions': total_decisions,\n",
    "            'strategy_distribution': self._analyze_strategy_distribution(decisions),\n",
    "            'decision_timing_analysis': self._analyze_decision_timing(decisions)\n",
    "        }\n",
    "    \n",
    "    def compare_ai_vs_baseline(self, data):\n",
    "        \"\"\"Compare AI performance vs baseline strategy\"\"\"\n",
    "        # Run AI-enhanced backtest\n",
    "        ai_results = self.backtesting_integrator.run_ai_enhanced_backtest(data)\n",
    "        \n",
    "        # Run baseline strategy (your original RSI2)\n",
    "        baseline_results = self._run_baseline_strategy(data)\n",
    "        \n",
    "        # Calculate performance comparison\n",
    "        comparison = {\n",
    "            'ai_performance': ai_results['performance_metrics'],\n",
    "            'baseline_performance': baseline_results['performance_metrics'],\n",
    "            'improvement_metrics': {\n",
    "                'return_improvement': ai_results['performance_metrics']['total_return'] - baseline_results['performance_metrics']['total_return'],\n",
    "                'sharpe_improvement': ai_results['performance_metrics']['sharpe_ratio'] - baseline_results['performance_metrics']['sharpe_ratio'],\n",
    "                'drawdown_improvement': baseline_results['performance_metrics']['max_drawdown'] - ai_results['performance_metrics']['max_drawdown'],\n",
    "            },\n",
    "            'statistical_significance': self._test_statistical_significance(ai_results, baseline_results)\n",
    "        }\n",
    "        \n",
    "        return comparison\n",
    "\n",
    "class PerformanceDashboard:\n",
    "    \"\"\"Real-time performance monitoring dashboard\"\"\"\n",
    "    \n",
    "    def __init__(self, validation_framework: AIValidationFramework):\n",
    "        self.validation_framework = validation_framework\n",
    "        self.performance_history = []\n",
    "        \n",
    "    def generate_comprehensive_report(self):\n",
    "        \"\"\"Generate detailed performance report\"\"\"\n",
    "        if not self.validation_framework.validation_results:\n",
    "            return \"No validation results available. Run validation suite first.\"\n",
    "        \n",
    "        results = self.validation_framework.validation_results\n",
    "        \n",
    "        report = f\"\"\"\n",
    "        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "                           AI TRADING AGENT PERFORMANCE REPORT\n",
    "        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        \n",
    "        ğŸ“Š OVERALL PERFORMANCE SUMMARY:\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        â€¢ Total Return: {results['out_of_sample']['performance_metrics']['total_return']:.2%}\n",
    "        â€¢ Sharpe Ratio: {results['out_of_sample']['performance_metrics']['sharpe_ratio']:.3f}\n",
    "        â€¢ Maximum Drawdown: {results['out_of_sample']['performance_metrics']['max_drawdown']:.2%}\n",
    "        â€¢ Win Rate: {results['ai_specific_metrics']['decision_accuracy']:.2%}\n",
    "        \n",
    "        ğŸ¤– AI-SPECIFIC METRICS:\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        â€¢ Decision Accuracy: {results['ai_specific_metrics']['decision_accuracy']:.2%}\n",
    "        â€¢ Average Confidence: {results['ai_specific_metrics']['average_confidence']:.3f}\n",
    "        â€¢ Total Decisions Made: {results['ai_specific_metrics']['total_decisions']}\n",
    "        â€¢ Confidence Calibration: {results['ai_specific_metrics']['confidence_calibration']:.3f}\n",
    "        \n",
    "        ğŸ“ˆ VALIDATION RESULTS:\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        â€¢ Walk Forward Consistency: {results['walk_forward']['consistency_score']:.3f}\n",
    "        â€¢ Monte Carlo Robustness: {results['monte_carlo']['robustness_score']:.3f}\n",
    "        â€¢ Cross Validation Score: {results['cross_validation']['avg_performance']:.3f}\n",
    "        \n",
    "        ğŸ¯ AI vs BASELINE COMPARISON:\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        â€¢ Return Improvement: {results['performance_comparison']['improvement_metrics']['return_improvement']:.2%}\n",
    "        â€¢ Sharpe Improvement: {results['performance_comparison']['improvement_metrics']['sharpe_improvement']:.3f}\n",
    "        â€¢ Drawdown Improvement: {results['performance_comparison']['improvement_metrics']['drawdown_improvement']:.2%}\n",
    "        \n",
    "        âœ… VALIDATION STATUS: {\"PASSED\" if self._overall_validation_passed(results) else \"NEEDS IMPROVEMENT\"}\n",
    "        \n",
    "        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        \"\"\"\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _overall_validation_passed(self, results):\n",
    "        \"\"\"Determine if AI agent passes validation criteria\"\"\"\n",
    "        criteria = [\n",
    "            results['ai_specific_metrics']['decision_accuracy'] > 0.55,  # > 55% accuracy\n",
    "            results['out_of_sample']['performance_metrics']['sharpe_ratio'] > 1.0,  # Sharpe > 1.0\n",
    "            results['performance_comparison']['improvement_metrics']['return_improvement'] > 0,  # Better than baseline\n",
    "            results['monte_carlo']['robustness_score'] > 0.7  # Robust performance\n",
    "        ]\n",
    "        \n",
    "        return sum(criteria) >= 3  # Pass if at least 3/4 criteria met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e338fa6",
   "metadata": {},
   "source": [
    "# PHASES 9-10: AGENT IMPROVEMENT & COMPLETE SYSTEM\n",
    "\n",
    "## PHASE 9: CONTINUOUS LEARNING & IMPROVEMENT\n",
    "\n",
    "### Self-Improving AI Agent:\n",
    "- **Performance Feedback Loop**: AI learns from trading results\n",
    "- **Parameter Optimization**: Dynamic tuning based on market conditions  \n",
    "- **Strategy Evolution**: AI develops new strategies over time\n",
    "- **Risk Adaptation**: AI adjusts risk tolerance based on performance\n",
    "- **Market Regime Recognition**: AI becomes better at identifying market phases\n",
    "\n",
    "### Learning Mechanisms:\n",
    "```python\n",
    "# Reinforcement learning from trading results\n",
    "# Bayesian optimization for parameter tuning\n",
    "# Ensemble methods for strategy combination\n",
    "# Online learning for real-time adaptation\n",
    "```\n",
    "\n",
    "## PHASE 10: COMPLETE TRADING SYSTEM INTEGRATION\n",
    "\n",
    "### Production-Ready System:\n",
    "1. **Real-Time Data Pipeline**: Live market data integration\n",
    "2. **Order Management System**: Safe trade execution\n",
    "3. **Risk Management Layer**: Position sizing, stop-losses, portfolio limits\n",
    "4. **Monitoring & Alerts**: Performance tracking, system health\n",
    "5. **Backup & Recovery**: Robust system architecture\n",
    "\n",
    "### Your Framework Integration Benefits:\n",
    "âœ… **Professional Foundation**: Your backtesting is institutional-quality  \n",
    "âœ… **Proven Strategies**: RSI2 and validation methods are battle-tested  \n",
    "âœ… **Risk Management**: Your position sizing and exits are sophisticated  \n",
    "âœ… **Performance Metrics**: Comprehensive evaluation framework  \n",
    "âœ… **Validation Suite**: Multiple validation methods ensure robustness  \n",
    "\n",
    "---\n",
    "\n",
    "# ğŸš€ IMPLEMENTATION ROADMAP\n",
    "\n",
    "## Quick Start (Weekend Project):\n",
    "1. **Setup Environment** (Phase 1) - 2 hours\n",
    "2. **Basic Data Pipeline** (Phase 2) - 3 hours  \n",
    "3. **Indicator Integration** (Phase 3) - 2 hours\n",
    "4. **Simple AI Agent** (Phase 4-5) - 4 hours\n",
    "\n",
    "## Professional Development (2-3 weeks):\n",
    "1. **Complete all phases** - Week 1-2\n",
    "2. **Extensive testing** - Week 2-3\n",
    "3. **Performance optimization** - Week 3\n",
    "4. **Documentation & deployment** - Week 3\n",
    "\n",
    "## Success Metrics:\n",
    "- **Outperform baseline RSI2 strategy**\n",
    "- **Sharpe ratio > 1.5**\n",
    "- **Maximum drawdown < 15%**\n",
    "- **Decision accuracy > 60%**\n",
    "- **Pass all validation tests**\n",
    "\n",
    "Your existing framework gives you a **massive head start**! Most quantitative trading systems take months to develop, but you already have the hard parts solved. The AI integration will add intelligence while preserving your proven foundation.\n",
    "\n",
    "**Ready to revolutionize your trading with AI? Let's start building! ğŸ¯**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
